{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents an example of using Principle Component Analysis.\n",
    "\n",
    "Date Created: 12 Feb 2018\n",
    "<br>\n",
    "Last Modified: 12 Feb 2018 \n",
    "<br>\n",
    "Humans Responsible: The Prickly Pythons\n",
    "<br>\n",
    "Kernel used: Python 2\n",
    "<br>\n",
    "<br>\n",
    "Most material below is from http://sebastianraschka.com/Articles/2014_pca_step_by_step.html\n",
    "<br>\n",
    "<br>\n",
    "Very nice slide presentation including Principle Component Regression: http://www.stats.uwo.ca/faculty/braun/ss3850/notes/sas10.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='illustration.png',width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration (and nice explanation) here: https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "np.random.seed(2342347) # random seed for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing a 3D dataset to a 2D dataset by dropping 1 dimension. \n",
    "<br>\n",
    "Start by creating some vectors of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vec1 = np.array([0,0,0])\n",
    "cov_mat1 = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "class1_sample = np.random.multivariate_normal(mu_vec1, cov_mat1, 20).T\n",
    "assert class1_sample.shape == (3,20), \"The matrix has not the dimensions 3x20\"\n",
    "\n",
    "mu_vec2 = np.array([1,1,1])\n",
    "cov_mat2 = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "class2_sample = np.random.multivariate_normal(mu_vec2, cov_mat2, 20).T\n",
    "assert class2_sample.shape == (3,20), \"The matrix has not the dimensions 3x20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.rcParams['legend.fontsize'] = 10   \n",
    "ax.plot(class1_sample[0,:], class1_sample[1,:], class1_sample[2,:], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
    "ax.plot(class2_sample[0,:], class2_sample[1,:], class2_sample[2,:], '^', markersize=8, alpha=0.5, color='red', label='class2')\n",
    "\n",
    "plt.title('Samples for class 1 and class 2')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don’t need class labels for the PCA analysis, let us merge the samples for our 2 classes into one 3×403×40-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = np.concatenate((class1_sample, class2_sample), axis=1)\n",
    "assert all_samples.shape == (3,40), \"The matrix has not the dimensions 3x40\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = np.mean(all_samples[0,:])\n",
    "mean_y = np.mean(all_samples[1,:])\n",
    "mean_z = np.mean(all_samples[2,:])\n",
    "\n",
    "mean_vector = np.array([[mean_x],[mean_y],[mean_z]])\n",
    "\n",
    "print('Mean Vector:\\n', mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix = np.zeros((3,3))\n",
    "for i in range(all_samples.shape[1]):\n",
    "    scatter_matrix += (all_samples[:,i].reshape(3,1) - mean_vector).dot((all_samples[:,i].reshape(3,1) - mean_vector).T)\n",
    "print('Scatter Matrix:\\n', scatter_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov([all_samples[0,:],all_samples[1,:],all_samples[2,:]])\n",
    "print('Covariance Matrix:\\n', cov_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computing eigenvectors and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvectors and eigenvalues for the from the scatter matrix\n",
    "eig_val_sc, eig_vec_sc = np.linalg.eig(scatter_matrix)\n",
    "\n",
    "# eigenvectors and eigenvalues for the from the covariance matrix\n",
    "eig_val_cov, eig_vec_cov = np.linalg.eig(cov_mat)\n",
    "\n",
    "for i in range(len(eig_val_sc)):\n",
    "    eigvec_sc = eig_vec_sc[:,i].reshape(1,3).T\n",
    "    eigvec_cov = eig_vec_cov[:,i].reshape(1,3).T\n",
    "    assert eigvec_sc.all() == eigvec_cov.all(), 'Eigenvectors are not identical'\n",
    "\n",
    "    print('Eigenvector {}: \\n{}'.format(i+1, eigvec_sc))\n",
    "    print('Eigenvalue {} from scatter matrix: {}'.format(i+1, eig_val_sc[i]))\n",
    "    print('Eigenvalue {} from covariance matrix: {}'.format(i+1, eig_val_cov[i]))\n",
    "    print('Scaling factor: ', eig_val_sc[i]/eig_val_cov[i])\n",
    "    print(40 * '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualize the eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(all_samples[0,:], all_samples[1,:], all_samples[2,:], 'o', markersize=8, color='green', alpha=0.2)\n",
    "ax.plot([mean_x], [mean_y], [mean_z], 'o', markersize=10, color='red', alpha=0.5)\n",
    "for v in eig_vec_sc.T:\n",
    "    a = Arrow3D([mean_x, v[0]], [mean_y, v[1]], [mean_z, v[2]], mutation_scale=20, lw=3, arrowstyle=\"-|>\", color=\"r\")\n",
    "    ax.add_artist(a)\n",
    "ax.set_xlabel('x_values')\n",
    "ax.set_ylabel('y_values')\n",
    "ax.set_zlabel('z_values')\n",
    "\n",
    "plt.title('Eigenvectors')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sorting the eigenvectors by decreasing eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ev in eig_vec_sc:\n",
    "    numpy.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "    \n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_val_sc[i]), eig_vec_sc[:,i]) for i in range(len(eig_val_sc))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choose k eigenvectors with the largest eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(3,1), eig_pairs[1][1].reshape(3,1)))\n",
    "print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transform the samples onto the new subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = matrix_w.T.dot(all_samples)\n",
    "assert transformed.shape == (2,40), \"The matrix is not 2x40 dimensional.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transformed[0,0:20], transformed[1,0:20], 'o', markersize=7, color='blue', alpha=0.5, label='class1')\n",
    "plt.plot(transformed[0,20:40], transformed[1,20:40], '^', markersize=7, color='red', alpha=0.5, label='class2')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.title('Transformed samples with class labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principle Component Regression will use the components with the most variance to do regression on a selected variable, see these slides (from slide number 11): http://www.stats.uwo.ca/faculty/braun/ss3850/notes/sas10.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
