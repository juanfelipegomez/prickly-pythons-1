{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains various examples of how to read in tabulated data in Python.\n",
    "\n",
    "Date Created: Fall 2016\n",
    "<br>\n",
    "Last Modified: Feb 5 2017 \n",
    "<br>\n",
    "Humans Responsible: The Prickly Pythons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data files in different formats in Python\n",
    "\n",
    "## 1.0 Starting with ASCII files!\n",
    "See links below for more information: \n",
    "<br>\n",
    "https://docs.python.org/3/howto/unicode.html\n",
    "<br>\n",
    "https://stackoverflow.com/questions/2241348/what-is-unicode-utf-8-utf-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(0b01000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(0x41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphrase = [0x4A, 0x65, 0x67, 0x20, 0x6C, \\\n",
    "           0xE6, 0x72, 0x65, 0x72, 0x20, \\\n",
    "           0x50, 0x79, 0x74, 0x68, 0x6F, \\\n",
    "           0x6E, 0x2E]\n",
    "\n",
    "for i in range(len(aphrase)):\n",
    "    print(chr(aphrase[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord('æ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(0x1F603)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Reading data in using numpy.loadtxt()\n",
    "Docs: http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In test_data/ there is a text file called spectrum.dat \n",
    "# with data that we want to load into python. \n",
    "# (spectrum.dat is a model stellar spectrum from starburst99 for \n",
    "# a group of stars with 0.7 x solar metallicity, \n",
    "# 1e4 solar masses population, Kroupa IMF and a starburst 1e6 years ago)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spec_nparray = np.loadtxt('test_data/spectrum.dat', skiprows=6)\n",
    "\n",
    "print(type(spec_nparray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of this numpy array will be determined by number of columns and rows in your data:\n",
    "print(spec_nparray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And if you want to extract e.g. the column containing wavelength data, \n",
    "# you need to remember its column index, in this case 1:\n",
    "wavelength_A = spec_nparray[:,1]\n",
    "\n",
    "print(wavelength_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, numbers are loaded with float 64 bit precision: \n",
    "print(wavelength_A.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Reading data in using numpy.genfromtxt()\n",
    "Doc: http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html\n",
    "\n",
    "The `genfromtxt()` function from numpy is a bit more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_nparray2 = np.genfromtxt('test_data/spectrum.dat', skip_header=6, \\\n",
    "                              names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular'])\n",
    "print(type(spec_nparray2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the seventh value in the wavelength column.\n",
    "print(spec_nparray[7,1])\n",
    "print(spec_nparray2['wavelength_A'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to change one of the wavelengths into something that is not a number (like %%%) \n",
    "# and you will see that genfromtxt() can handle this if you specify the keywords:\n",
    "# missing_values='%%%', filling_values=desired_value\n",
    "spec_nparray2 = np.genfromtxt('test_data/spectrum_nan.dat', skip_header=6,\\\n",
    "                              names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular'],\\\n",
    "                              missing_values='%%%', filling_values=np.nan)\n",
    "\n",
    "print(spec_nparray2['wavelength_A'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But loadtxt() will crash:\n",
    "spec_nparray = np.loadtxt('test_data/spectrum_nan.dat', skiprows=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Read data into Pandas dataframe\n",
    "Typically, a smarter way (if you are essentially loading a matrix) is to load the data directly into a Pandas DataFrame. The function read_table (almost identical to read_table) can be used to read an ascii file into a dataframe:<br>\n",
    "http://pandas.pydata.org/pandas-docs/stable/dsintro.html<br>\n",
    "Some attractive functionalities in Pandas that can be applied to a DataFrame:<br>\n",
    "http://dataconomy.com/2015/03/14-best-python-pandas-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular']\n",
    "spec_dataframe = pd.read_table('test_data/spectrum.dat', \\\n",
    "                               names=names,              \\\n",
    "                               skiprows=6,               \\\n",
    "                               sep=r\"\\s*\",               \\\n",
    "                               engine='python')    \n",
    "print(type(spec_dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about engine: The C engine is faster while the python engine is currently more feature-complete. The C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, csv.Sniffer. In addition, separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dataframe['t_yr'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['xtick.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "fig          =   plt.figure(0, figsize=(10,5))\n",
    "ax1          =   fig.add_axes([0.15,0.1,0.75,0.8])\n",
    "ax1.set_ylim(31,39)\n",
    "ax1.set_xlim(1e2,1e6)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Wavelength [AA]', fontsize=15)\n",
    "ax1.set_ylabel('log flux [erg/s/AA]', fontsize=15)\n",
    "ax1.set_title('1e4 M$_{\\odot}$ of stars with Z=0.008 after 1e6 yr', fontsize=15)#+str(t1)+' yr')\n",
    "#ax1.plot(spec_nparray[:,1],spec_nparray[:,2],'b')\n",
    "#ax1.plot(spec_nparray2['wavelength'],spec_nparray2['L_tot'],'b')\n",
    "ax1.plot(spec_dataframe['wavelength_A'], spec_dataframe['L_tot'],'b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a function that saves (serializes) a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dataframe.to_pickle('test_data/spec_dataframe_pickle') # no extension\n",
    "load_spec_dataframe_pickle = pd.read_pickle('test_data/spec_dataframe_pickle')\n",
    "load_spec_dataframe_pickle['t_yr'][0] # test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the to_pickle function will use the highest \"protocol\" possible to save the dataframe in binary format: \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_pickle.html\n",
    "\n",
    "Protocol version 0 is the original ASCII protocol and is backwards compatible with earlier versions of Python.<br>\n",
    "Protocol version 1 is the old binary format which is also compatible with earlier versions of Python.<br>\n",
    "Protocol version 2 was introduced in Python 2.3. It provides much more efficient pickling of new-style classes.\n",
    "\n",
    "To check what your default highest protocol is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "pickle.HIGHEST_PROTOCOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here protocol=2 was used. Forcing protocol=0, results in a slightly larger datafile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "spec_dataframe.to_pickle('test_data/spec_dataframe_pickle_p0',protocol=0) # no extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately it depends a bit on what the dataframe contains, see a comparison here of different ways to save dataframes: \n",
    "http://matthewrocklin.com/blog/work/2015/03/16/Fast-Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 `Fits` files from astropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In test_data/ there is a file called cloud.fits with data that we want to import into python. \n",
    "(cloud.fits is a simulated HCO+ data cube of a cloud, calculated with the radiative transfer code LIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need the fits module from astropy.io to open the fits file as a class object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "fits_file = fits.open('test_data/cloud.fits')\n",
    "print(type(fits_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(HDU = Header Data Unit)<br>\n",
    "Next, we can get some basic info about the fits file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And display all header \"cards\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fits_file[0].header) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the info that we're interested in like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgres = fits_file[0].header['CDELT2']\n",
    "print('Image resolution: %.6s degrees ' % imgres)\n",
    "npix = fits_file[0].header['NAXIS3']\n",
    "print('Number of pixels on each side: %s' % npix)\n",
    "velres = fits_file[0].header['CDELT3']\n",
    "print('Velocity resolution: %s m/s' % velres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can change any of these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_file[0].header['CDELT2']=2.0\n",
    "imgres = fits_file[0].header['CDELT2']\n",
    "print('Image resolution: %.6s degrees ' % imgres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data is an attribute of data[0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCO_flux = fits_file[0].data \n",
    "print(np.shape(HCO_flux))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I know that the 60x100x100 matrix is in the format [velocity channels, x axis, y axis], so we can create the moment 0 map as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom0 = HCO_flux.sum(axis=0)*velres/1000 # moment 0 map, Jy*km/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make a contour plot of this map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig         =   plt.figure(1,figsize=(9,9))\n",
    "ax1         =   fig.add_subplot(1,1,1)\n",
    "ax1.set_xlabel(\"x ['']\",fontsize=15)\n",
    "ax1.set_ylabel(\"y ['']\",fontsize=15)\n",
    "ax1.set_title(\"Moment 0 map of HCO$^+$ gas cloud\",fontsize=15)\n",
    "x1 = imgres*(np.arange(npix)-npix/2) # image axis\n",
    "xmax = max(x1)\n",
    "im = ax1.imshow(mom0,interpolation='bilinear',origin='lower',\\\n",
    "                cmap=cm.hot,extent=(-xmax,xmax,-xmax,xmax),vmax=120)\n",
    "# Add colorbar that matches image in height\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(im,cax=cax)\n",
    "cbar.set_label('Jy km/s',size=20)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Saving data for later with numpy\n",
    "Docs: \n",
    "<br>\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html\n",
    "<br>\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say you have a numpy array that you want to save to a file and load later. \n",
    "# One way to do so is with numpy:\n",
    "np.save('test_data/spec_nparray', spec_nparray) # will get a '.npy' extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - using numpy.load()\n",
    "load_spec_nparray = np.load('test_data/spec_nparray.npy')\n",
    "load_spec_nparray[7,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pickling\n",
    "Docs: \n",
    "<br>\n",
    "https://docs.python.org/3/library/pickle.html\n",
    "<br>\n",
    "https://docs.python.org/2.3/lib/module-cPickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use pickle! Or cPickle, which is pickle written in C, \n",
    "# with several advantages.\n",
    "import cPickle as pickle\n",
    "\n",
    "pickle.dump(spec_nparray, open('test_data/spec_nparray_pickle','wb')) # no extension\n",
    "# 'wb' is the protocol and means to write to binary format\n",
    "load_spec_nparray = pickle.load(open('test_data/spec_nparray_pickle','rb'))\n",
    "load_spec_nparray[7,1] # Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But the to_pickle attribute is specific to pandas and will not work on say a numpy array:\n",
    "spec_nparray.to_pickle('test_data/spec_dataframe_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
